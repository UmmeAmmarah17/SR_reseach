{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12330219,"sourceType":"datasetVersion","datasetId":7772618}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Super-Resolution for Remote Sensing Images via Local-Global-Combined Network (2017)**\n```\n@article{lei2017super,\n  title={Super-resolution for remote sensing images via local--global combined network},\n  author={Lei, Sen and Shi, Zhenwei and Zou, Zhengxia},\n  journal={IEEE Geoscience and Remote Sensing Letters},\n  volume={14},\n  number={8},\n  pages={1243--1247},\n  year={2017},\n  publisher={IEEE}\n}\n```\n1. **Model Definition**\n  * Complete LGCNet model (conv1 to conv7) with exact layer shapes and skip connection (residual learning).\n  * Uses ReLU after each conv.\n  * Combines outputs of conv3, conv4, and conv5 using torch.cat and a 5×5 convolution.\n\n2. **Training Process**\n  * Mean squared error (MSE) loss\n  * SGD optimizer (initial LR=0.1, momentum=0.9, weight decay=1e-4)\n  * LR decays by 10× after 40 epochs (scheduler)\n  * Gradient clipping using L2 norm\n  * 80 epochs in total, batch size = 128\n\n3. **Dataset**\n  * Extracts 41×41 patches\n  * LR is created by downsampling & then upsampling using bicubic\n  * Training/Validation split (80/20)\n\n4. **Metrics**\n  * PSNR implemented\n  * SSIM to be added optionally (using skimage.metrics.structural_similarity)","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport random\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom skimage.metrics import structural_similarity as compare_ssim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:43:54.568414Z","iopub.execute_input":"2025-06-30T12:43:54.568659Z","iopub.status.idle":"2025-06-30T12:44:02.761366Z","shell.execute_reply.started":"2025-06-30T12:43:54.568639Z","shell.execute_reply":"2025-06-30T12:44:02.760638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RemoteSensingDataset(Dataset):\n    def __init__(self, image_paths, patch_size=41, scale=3):\n        self.image_paths = image_paths\n        self.patch_size = patch_size\n        self.scale = scale\n        self.hr_transform = T.ToTensor()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert('RGB')\n        img = np.array(img)\n        h, w, _ = img.shape\n        ps = self.patch_size\n        x = random.randint(0, w - ps - 1)\n        y = random.randint(0, h - ps - 1)\n        hr = img[y:y+ps, x:x+ps, :]\n        lr = cv2.resize(hr, (ps//self.scale, ps//self.scale), interpolation=cv2.INTER_CUBIC)\n        lr_up = cv2.resize(lr, (ps, ps), interpolation=cv2.INTER_CUBIC)\n        hr = self.hr_transform(Image.fromarray(hr))\n        lr_up = self.hr_transform(Image.fromarray(lr_up))\n        return lr_up, hr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:44:11.802991Z","iopub.execute_input":"2025-06-30T12:44:11.803784Z","iopub.status.idle":"2025-06-30T12:44:11.809709Z","shell.execute_reply.started":"2025-06-30T12:44:11.803759Z","shell.execute_reply":"2025-06-30T12:44:11.808965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n\n# Define the Local-Global-Combined Network (LGCNet)\nclass LGCNet(nn.Module):\n    def __init__(self, in_channels=3):\n        super(LGCNet, self).__init__()\n\n        # === Representation Layers ===\n        # 5 convolutional layers with 3x3 kernels and 32 feature maps\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n        self.conv5 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n        # === Local-Global-Combination Layer ===\n        # Concatenate conv3, conv4, conv5 -> input channels = 32 * 3 = 96\n        # Then apply a 5x5 convolution to combine them\n        self.lgc_merge = nn.Sequential(\n            nn.Conv2d(96, 64, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True)\n        )\n\n        # === Reconstruction Layer ===\n        # Output residual with 3x3 conv and add it to input\n        self.reconstruct = nn.Conv2d(64, in_channels, kernel_size=3, padding=1)\n\n    def forward(self, x):\n        # Save input to add residual later\n        input_lr = x\n\n        # Representation path\n        x1 = self.conv1(x)\n        x2 = self.conv2(x1)\n        x3 = self.conv3(x2)\n        x4 = self.conv4(x3)\n        x5 = self.conv5(x4)\n\n        # Local-global combination using conv3, conv4, conv5\n        combined = torch.cat((x3, x4, x5), dim=1)\n        fused = self.lgc_merge(combined)\n\n        # Reconstruct residual and add it to the input image\n        residual = self.reconstruct(fused)\n        output = input_lr + residual\n\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:44:27.051825Z","iopub.execute_input":"2025-06-30T12:44:27.052402Z","iopub.status.idle":"2025-06-30T12:44:27.059334Z","shell.execute_reply.started":"2025-06-30T12:44:27.052377Z","shell.execute_reply":"2025-06-30T12:44:27.058654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calc_psnr(sr, hr):\n    mse = ((sr - hr) ** 2).mean()\n    if mse == 0:\n        return 100\n    return 20 * math.log10(1.0 / math.sqrt(mse))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:44:30.145866Z","iopub.execute_input":"2025-06-30T12:44:30.146660Z","iopub.status.idle":"2025-06-30T12:44:30.151319Z","shell.execute_reply.started":"2025-06-30T12:44:30.146626Z","shell.execute_reply":"2025-06-30T12:44:30.150601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, dataloader, device, num_epochs=20):\n    criterion = nn.MSELoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n    model.train()\n    for epoch in range(num_epochs):\n        epoch_loss = 0\n        for lr, hr in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            lr, hr = lr.to(device), hr.to(device)\n            sr = model(lr)\n            loss = criterion(sr, hr)\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.4)\n            optimizer.step()\n            epoch_loss += loss.item()\n        scheduler.step()\n        print(f\"Epoch {epoch+1} Loss: {epoch_loss/len(dataloader):.6f}\")\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:44:31.962740Z","iopub.execute_input":"2025-06-30T12:44:31.963163Z","iopub.status.idle":"2025-06-30T12:44:31.968774Z","shell.execute_reply.started":"2025-06-30T12:44:31.963136Z","shell.execute_reply":"2025-06-30T12:44:31.967987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate_model(model, image_paths, device, scale=3):\n    model.eval()\n    psnr_scores = []\n    ssim_scores = []\n\n    for img_path in tqdm(image_paths, desc=\"Validating\"):\n        img = Image.open(img_path).convert('RGB')\n        img = np.array(img).astype(np.float32)/255.0\n        h, w, _ = img.shape\n        h -= h%scale\n        w -= w%scale\n        img = img[:h,:w,:]\n\n        lr = cv2.resize(img, (w//scale, h//scale), interpolation=cv2.INTER_CUBIC)\n        lr_up = cv2.resize(lr, (w, h), interpolation=cv2.INTER_CUBIC)\n\n        lr_tensor = torch.from_numpy(lr_up.transpose(2,0,1)).unsqueeze(0).to(device)\n        hr_tensor = torch.from_numpy(img.transpose(2,0,1)).unsqueeze(0).to(device)\n\n        with torch.no_grad():\n            sr_tensor = model(lr_tensor).clamp(0,1)\n\n        # Convert to NumPy\n        sr = sr_tensor.squeeze().cpu().numpy().transpose(1,2,0)\n        hr = hr_tensor.squeeze().cpu().numpy().transpose(1,2,0)\n\n        # Compute metrics\n        psnr = calc_psnr(sr, hr)\n        ssim = compare_ssim(sr, hr, multichannel=True, data_range=1.0, channel_axis=2)\n\n        psnr_scores.append(psnr)\n        ssim_scores.append(ssim)\n\n        # Immediately delete large arrays\n        del lr_tensor, hr_tensor, sr_tensor, sr, hr\n        torch.cuda.empty_cache()\n\n    print(f\"\\nAverage PSNR: {np.mean(psnr_scores):.2f} dB\")\n    print(f\"Average SSIM: {np.mean(ssim_scores):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T13:04:44.862302Z","iopub.execute_input":"2025-06-30T13:04:44.862590Z","iopub.status.idle":"2025-06-30T13:04:44.869989Z","shell.execute_reply.started":"2025-06-30T13:04:44.862572Z","shell.execute_reply":"2025-06-30T13:04:44.869257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def super_resolve_single_image(model, image_path, device, scale=3):\n    model.eval()\n    img = Image.open(image_path).convert('RGB')\n    img = np.array(img).astype(np.float32)/255.0\n    h, w, _ = img.shape\n    h -= h%scale\n    w -= w%scale\n    img = img[:h,:w,:]\n    lr = cv2.resize(img, (w//scale, h//scale), interpolation=cv2.INTER_CUBIC)\n    lr_up = cv2.resize(lr, (w, h), interpolation=cv2.INTER_CUBIC)\n    lr_tensor = torch.from_numpy(lr_up.transpose(2,0,1)).unsqueeze(0).to(device)\n    with torch.no_grad():\n        sr_tensor = model(lr_tensor).clamp(0,1)\n    sr = sr_tensor.squeeze().cpu().numpy().transpose(1,2,0)\n    plt.figure(figsize=(12,4))\n    plt.subplot(1,3,1); plt.title(\"Bicubic\"); plt.imshow(lr_up); plt.axis(\"off\")\n    plt.subplot(1,3,2); plt.title(\"Super-Resolved\"); plt.imshow((sr*255).astype(np.uint8)); plt.axis(\"off\")\n    plt.subplot(1,3,3); plt.title(\"Original\"); plt.imshow((img*255).astype(np.uint8)); plt.axis(\"off\")\n    plt.tight_layout(); plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:44:38.508345Z","iopub.execute_input":"2025-06-30T12:44:38.508615Z","iopub.status.idle":"2025-06-30T12:44:38.515520Z","shell.execute_reply.started":"2025-06-30T12:44:38.508594Z","shell.execute_reply":"2025-06-30T12:44:38.514794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Change this path to your uploaded images folder\nimage_folder = \"/kaggle/input/satellite-images/train_sm\"\n\n# Load images\nimage_paths = glob(os.path.join(image_folder, '*.jpg')) + \\\n              glob(os.path.join(image_folder, '*.png')) + \\\n              glob(os.path.join(image_folder, '*.jpeg'))\n\nrandom.shuffle(image_paths)\nsplit = int(0.8 * len(image_paths))\ntrain_paths = image_paths[:split]\nval_paths = image_paths[split:]\n\ntrain_dataset = RemoteSensingDataset(train_paths)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = LGCNet().to(device)\n\n# Train\ntrained_model = train_model(model, train_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:44:52.923034Z","iopub.execute_input":"2025-06-30T12:44:52.923316Z","iopub.status.idle":"2025-06-30T12:50:04.597992Z","shell.execute_reply.started":"2025-06-30T12:44:52.923297Z","shell.execute_reply":"2025-06-30T12:50:04.597129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import h5py\nwith h5py.File('model_weights.h5', 'w') as f:\n        for k, v in model.state_dict().items():\n            f.create_dataset(k, data=v.cpu().numpy()) # Convert tensor to numpy array and move to CPU if on GPU\n#model.save('lgcnet_sr.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T12:58:53.493451Z","iopub.execute_input":"2025-06-30T12:58:53.494051Z","iopub.status.idle":"2025-06-30T12:58:53.687640Z","shell.execute_reply.started":"2025-06-30T12:58:53.494025Z","shell.execute_reply":"2025-06-30T12:58:53.687116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the weights from the .h5 file\n    loaded_state_dict = {}\n    with h5py.File('model_weights.h5', 'r') as f:\n        for k in f.keys():\n            loaded_state_dict[k] = torch.from_numpy(f[k][:])\n\n    # Create an instance of your model\n    loaded_model = MyModel()\n\n    # Load the state_dict into the model\n    loaded_model.load_state_dict(loaded_state_dict)\n    loaded_model.eval() # Set model to evaluation mode","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Validate\nvalidate_model(trained_model, val_paths, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T13:04:59.008375Z","iopub.execute_input":"2025-06-30T13:04:59.008630Z","iopub.status.idle":"2025-06-30T13:10:06.437062Z","shell.execute_reply.started":"2025-06-30T13:04:59.008614Z","shell.execute_reply":"2025-06-30T13:10:06.436225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test on a single image\nsuper_resolve_single_image(trained_model, val_paths[0], device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T13:10:11.800538Z","iopub.execute_input":"2025-06-30T13:10:11.801268Z","iopub.status.idle":"2025-06-30T13:10:16.557461Z","shell.execute_reply.started":"2025-06-30T13:10:11.801244Z","shell.execute_reply":"2025-06-30T13:10:16.556661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}